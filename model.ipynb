{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for cs5785 final, Team Ground Truth\n",
    "### 2. Model part\n",
    "- Author:  Hongliang CHI, hc962@cornell.edu,Kai Zhang kz298@cornell.edu\n",
    "\n",
    "- Please make sure to have generated Resent features in the fold that this file in; The augmented Resent features can be generated by running \"extract_resnet_features OR download through Google drive. Please read README for further details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import gensim\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.stem.porter import PorterStemmer  \n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.externals import joblib\n",
    "import gc\n",
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the train,validation and testing set index\n",
    "num_train = 8000\n",
    "num_dev = 2000\n",
    "num_test = 2000\n",
    "split_idx = list(range(num_train + num_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = '!.,;:?\"\\''\n",
    "def removePunctuation(text):\n",
    "    text = re.sub(r'[{}]+'.format(punctuation),'',text)\n",
    "    return text.strip().lower()\n",
    "\n",
    "def parse_descriptions(data_dir, num_doc):\n",
    "    docs = []\n",
    "    for i in range(num_doc):\n",
    "        path = os.path.join(data_dir, \"%d.txt\" % i)\n",
    "        with open(path) as f:\n",
    "            docs.append(f.read())\n",
    "    return docs\n",
    "\n",
    "def parse_features(features_path):\n",
    "    vec_map = {}\n",
    "    with open(features_path) as f:\n",
    "        for row in csv.reader(f):\n",
    "            img_id = int(row[0].split(\"/\")[1].split(\".\")[0])\n",
    "            vec_map[img_id] = np.array([float(x) for x in row[1:]])\n",
    "    return np.array([v for k, v in sorted(vec_map.items())])\n",
    "\n",
    "def doc_to_vec(sentence, word2vec):\n",
    "    # get list of word vectors in sentence\n",
    "    stop_words = set(['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its',\n",
    "'before', 'herself', 'had', 'should', 'to', 'only', 'under', 'ours', 'has', 'do',\n",
    "'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'did', 'this',\n",
    "'she', 'each', 'further', 'where', 'few', 'because', 'doing', 'some', 'are', 'our',\n",
    "'ourselves', 'out', 'what', 'for', 'while', 'does', 'above', 'between', 't', 'be',\n",
    "'we', 'who', 'were', 'here', 'hers', 'by', 'on', 'about', 'of', 'against', 's', 'or',\n",
    "'own', 'into', 'yourself', 'down', 'your', 'from', 'her', 'their', 'there', 'been',\n",
    "'whom', 'too', 'themselves', 'was', 'until', 'more', 'himself', 'that', 'but', 'don',\n",
    "'with', 'than', 'those', 'he', 'me', 'myself', 'these', 'up', 'will', 'below', 'can',\n",
    "'theirs', 'my', 'and', 'then', 'is', 'am', 'it', 'an', 'as', 'itself', 'at', 'have',\n",
    "'in', 'any', 'if', 'again', 'no', 'when', 'same', 'how', 'other', 'which', 'you',\n",
    "'after', 'most', 'such', 'why', 'a', 'off', 'i', 'yours', 'so', 'the', 'having',\n",
    "'once'])\n",
    "    word_tokens = word_tokenize(removePunctuation(sentence))\n",
    "    filtered_sentence = list(set([w for w in word_tokens if not w in stop_words]))\n",
    "    word_vecs = [word2vec.get_vector(w) for w in filtered_sentence if w in word2vec.wv.vocab]\n",
    "    if len(word_vecs) == 0 :\n",
    "        return np.zeros(300)\n",
    "    return np.stack(word_vecs).mean(0)\n",
    "\n",
    "def sentence_filter(sentence):\n",
    "      # text cleansing for Bag of words BOW\n",
    "    lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "    stop_words = set(['all', 'just', 'being', 'over', 'both', 'through', 'yourselves', 'its',\n",
    "'before', 'herself', 'had', 'should', 'to', 'only', 'under', 'ours', 'has', 'do',\n",
    "'them', 'his', 'very', 'they', 'not', 'during', 'now', 'him', 'nor', 'did', 'this',\n",
    "'she', 'each', 'further', 'where', 'few', 'because', 'doing', 'some', 'are', 'our',\n",
    "'ourselves', 'out', 'what', 'for', 'while', 'does', 'above', 'between', 't', 'be',\n",
    "'we', 'who', 'were', 'here', 'hers', 'by', 'on', 'about', 'of', 'against', 's', 'or',\n",
    "'own', 'into', 'yourself', 'down', 'your', 'from', 'her', 'their', 'there', 'been',\n",
    "'whom', 'too', 'themselves', 'was', 'until', 'more', 'himself', 'that', 'but', 'don',\n",
    "'with', 'than', 'those', 'he', 'me', 'myself', 'these', 'up', 'will', 'below', 'can',\n",
    "'theirs', 'my', 'and', 'then', 'is', 'am', 'it', 'an', 'as', 'itself', 'at', 'have',\n",
    "'in', 'any', 'if', 'again', 'no', 'when', 'same', 'how', 'other', 'which', 'you',\n",
    "'after', 'most', 'such', 'why', 'a', 'off', 'i', 'yours', 'so', 'the', 'having',\n",
    "'once'])\n",
    "    word_tokens = word_tokenize(removePunctuation(sentence))\n",
    "    filtered_sentence = list(set([w for w in word_tokens if not w in stop_words]))\n",
    "    filtered_sentence = filtered_sentence + [lemma.lemmatize(i) for i in filtered_sentence]\n",
    "    # there may be empty \n",
    "    if len(sentence) == 0 :\n",
    "        return ''\n",
    "    return ' '.join(filtered_sentence)\n",
    "\n",
    "def dist_matrix(x1, x2):\n",
    "    #cosine distance\n",
    "    return np.array([cosine(i,j ) for i in x1 for j in x2]).reshape(2000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Read and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in Google word2vec model\n",
    "word2vec = gensim.models.KeyedVectors.\\\n",
    "            load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all word2vec description!\n",
      "x_train_vec shape: (8000, 300)\n",
      "x_dev_vec shape: (2000, 300)\n",
      "x_test_vec shape: (2000, 300)\n"
     ]
    }
   ],
   "source": [
    "# read in word2vec description model\n",
    "train_dev_desc = parse_descriptions(\"./descriptions_train\", num_doc=(num_train+num_dev))\n",
    "test_desc = parse_descriptions(\"./descriptions_test\", num_doc=num_test)\n",
    "x_train_vec = np.array([doc_to_vec(train_dev_desc[i], word2vec) for i in split_idx[:num_train]])\n",
    "x_dev_vec = np.array([doc_to_vec(train_dev_desc[i], word2vec) for i in split_idx[num_train:]])\n",
    "x_test_vec = np.array([doc_to_vec(d, word2vec) for d in test_desc])\n",
    "\n",
    "print(\"Built all word2vec description!\")\n",
    "print(\"x_train_vec shape:\", x_train_vec.shape)\n",
    "print(\"x_dev_vec shape:\", x_dev_vec.shape)\n",
    "print(\"x_test_vec shape:\", x_test_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all word2vec tags!\n",
      "x_train_tag shape: (8000, 300)\n",
      "x_dev_tag shape: (2000, 300)\n",
      "x_test_tag shape: (2000, 300)\n"
     ]
    }
   ],
   "source": [
    "# read in word2vec tags model\n",
    "train_dev_tag = parse_descriptions(\"./tags_train\", num_doc=(num_train+num_dev))\n",
    "test_tag = parse_descriptions(\"./tags_test\", num_doc=num_test)\n",
    "x_train_tag = np.array([doc_to_vec(train_dev_tag[i], word2vec) for i in split_idx[:num_train]])\n",
    "x_dev_tag = np.array([doc_to_vec(train_dev_tag[i], word2vec) for i in split_idx[num_train:]])\n",
    "x_test_tag = np.array([doc_to_vec(d, word2vec) for d in test_tag])\n",
    "\n",
    "print(\"Built all word2vec tags!\")\n",
    "print(\"x_train_tag shape:\", x_train_tag.shape)\n",
    "print(\"x_dev_tag shape:\", x_dev_tag.shape)\n",
    "print(\"x_test_tag shape:\", x_test_tag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all BOW description!\n",
      "x_train_bow shape: (8000, 10634)\n",
      "x_dev_bow shape: (2000, 10634)\n",
      "X_test_bow  shape: (2000, 10634)\n"
     ]
    }
   ],
   "source": [
    "# read in BOW description model\n",
    "vectorizer = CountVectorizer(min_df= 1,max_df = 0.50)\n",
    "X = vectorizer.fit_transform([sentence_filter(d) for d in train_dev_desc+ test_desc]).toarray()\n",
    "#X_train_bow = vectorizer.transform(np.array([sentence_filter(train_dev_desc[i]) for i in split_idx])).toarray()\n",
    "#train test split\n",
    "x_train_bow = X [:8000,:]\n",
    "x_dev_bow =X[8000:10000,:]\n",
    "X_test_bow = X [10000:,:]\n",
    "# for submission output\n",
    "x_train_all_bow = x_train_bow\n",
    "\n",
    "print(\"Built all BOW description!\")\n",
    "print(\"x_train_bow shape:\", x_train_bow.shape)\n",
    "print(\"x_dev_bow shape:\", x_dev_bow.shape)\n",
    "print(\"X_test_bow  shape:\",X_test_bow .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all BOW tag!\n",
      "tag_train_bow shape: (8000, 93)\n",
      "tag_dev_bow shape: (2000, 93)\n",
      "tag_test_bow  shape: (2000, 93)\n"
     ]
    }
   ],
   "source": [
    "# read in BOW tag model\n",
    "vectorizer = CountVectorizer(min_df= 1,max_df = 0.50)\n",
    "tag_test_bow = vectorizer.fit_transform([sentence_filter(d) for d in test_tag]).toarray()\n",
    "tag_train_bow = vectorizer.transform(np.array([sentence_filter(train_dev_tag[i]) for i in split_idx])).toarray()\n",
    "#train test split\n",
    "tag_dev_bow =tag_train_bow[8000:10000,:]\n",
    "tag_train_bow = tag_train_bow [:8000,:]\n",
    "\n",
    "print(\"Built all BOW tag!\")\n",
    "print(\"tag_train_bow shape:\", tag_train_bow.shape)\n",
    "print(\"tag_dev_bow shape:\", tag_dev_bow.shape)\n",
    "print(\"tag_test_bow  shape:\",tag_test_bow .shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all resnet ori 1000!\n",
      "y_train shape: (8000, 1000)\n",
      "y_dev shape: (2000, 1000)\n",
      "y_test shape: (2000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# read in baseline provided resnet1000\n",
    "y_train_dev = parse_features(\"features_train/features_resnet1000_train.csv\") \n",
    "y_train = y_train_dev[split_idx[:num_train]]\n",
    "y_dev = y_train_dev[split_idx[num_train:]]\n",
    "y_test = parse_features(\"features_test/features_resnet1000_test.csv\") \n",
    "\n",
    "print(\"Built all resnet ori 1000!\")\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_dev shape:\", y_dev.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built all resnet ori 2048!\n",
      "y2_train shape: (8000, 2048)\n",
      "y2_dev shape: (2000, 2048)\n",
      "y2_test shape: (2000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# read in baseline provided resnet2048\n",
    "y2_train_dev = parse_features(\"features_train/features_resnet1000intermediate_train.csv\") \n",
    "y2_train = y2_train_dev[split_idx[:num_train]]\n",
    "y2_dev = y2_train_dev[split_idx[num_train:]]\n",
    "y2_test = parse_features(\"features_test/features_resnet1000intermediate_test.csv\")\n",
    "\n",
    "print(\"Built all resnet ori 2048!\")\n",
    "print(\"y2_train shape:\", y2_train.shape)\n",
    "print(\"y2_dev shape:\", y2_dev.shape)\n",
    "print(\"y2_test shape:\", y2_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [caution]\n",
    "- The following files can be generated by running the feature generating code in the other notebook or download from https://drive.google.com/drive/folders/1pkXLFcvuEkC_VQ-QunVUC9EjjlvF8-j5?usp=sharing (generated_resenet_features.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in self generated reset feature\n",
    "resnet50_train = pd.read_csv('resnet50_train.csv')\n",
    "resnet101_train = pd.read_csv('resnet101_train.csv')\n",
    "resnet152_train = pd.read_csv('resnet152_train.csv')\n",
    "resnetnext_train = pd.read_csv('resnet_ResNext_train.csv')\n",
    "resnetwide_train = pd.read_csv('resnet_wide101_train.csv')\n",
    "\n",
    "resnet50_test = pd.read_csv('resnet50_test.csv')\n",
    "resnet101_test = pd.read_csv('resnet101_test.csv')\n",
    "resnet152_test = pd.read_csv('resnet152_test.csv')\n",
    "resnetnext_test = pd.read_csv('resnet_ResNext_test.csv')\n",
    "resnetwide_test = pd.read_csv('resnet_wide101_test.csv')\n",
    "\n",
    "#merge data\n",
    "y_train_allpic_bowcaptag_s = np.hstack([y_train,y2_train,\\\n",
    "                      resnet50_train[[str(i) for i in range(3048)]].values[:8000,:],\\\n",
    "                     resnet101_train[[str(i) for i in range(3048)]].values[:8000,:],\\\n",
    "                      resnet152_train[[str(i) for i in range(3048)]].values[:8000,:],\\\n",
    "                    resnetnext_train[[str(i) for i in range(3048)]].values[:8000,:],\\\n",
    "                      resnetwide_train[[str(i) for i in range(3048)]].values[:8000,:],\\\n",
    "                                      tag_train_bow ])\n",
    "\n",
    "y_dev_allpic_bowcaptag_s = np.hstack([y_dev,y2_dev,\\\n",
    "                      resnet50_train[[str(i) for i in range(3048)]].values[8000:,:],\\\n",
    "                     resnet101_train[[str(i) for i in range(3048)]].values[8000:,:],\\\n",
    "                      resnet152_train[[str(i) for i in range(3048)]].values[8000:,:],\\\n",
    "                    resnetnext_train[[str(i) for i in range(3048)]].values[8000:,:],\\\n",
    "                      resnetwide_train[[str(i) for i in range(3048)]].values[8000:,:],\\\n",
    "                                    tag_dev_bow])\n",
    "\n",
    "y_test_allpic_bowcaptag_s = np.hstack([y_test,y2_test,\\\n",
    "                      resnet50_test[[str(i) for i in range(3048)]].values,\\\n",
    "                     resnet101_test[[str(i) for i in range(3048)]].values,\\\n",
    "                      resnet152_test[[str(i) for i in range(3048)]].values,\\\n",
    "                    resnetnext_test[[str(i) for i in range(3048)]].values,\\\n",
    "                      resnetwide_test[[str(i) for i in range(3048)]].values,\\\n",
    "                                     tag_test_bow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performer\n",
    "### 4 kernel ridge regressions ensmeble on augemented Resnet features + Tag BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Word2Vec Kernel Ridge(Y= w2v des) - rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 300)\n",
      "(10000, 18381)\n",
      "KernelRidge(alpha=1, coef0=1, degree=3, gamma=None, kernel='rbf',\n",
      "      kernel_params=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train_all = np.concatenate([x_train_vec, x_dev_vec])\n",
    "y_train_all_pic_bowcaptag_s = np.concatenate([y_train_allpic_bowcaptag_s, y_dev_allpic_bowcaptag_s])\n",
    "\n",
    "parameters = {\"alpha\": [0.01,0.1,1,2,3,5,10],'gamma':[0.01,0.1, 1], \"kernel\":['rbf']}\n",
    "reg_vec_k_s = GridSearchCV(KernelRidge(), parameters, cv=5,n_jobs=-1)\n",
    "print (x_train_all.shape)\n",
    "print (y_train_all_pic_bowcaptag_s.shape)\n",
    "reg_vec_k_s.fit(y_train_all_pic_bowcaptag_s,x_train_all)\n",
    "print (reg_vec_k_s.best_estimator_)\n",
    "\n",
    "x_test_pred_rid_vec_2_k_s = reg_vec_k_s.predict(y_test_allpic_bowcaptag_s)\n",
    "test_distances_rid_vec_2_k_s = dist_matrix(x_test_pred_rid_vec_2_k_s , x_test_vec).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Word2Vec Kernel Ridge(Y= w2v des) - ploynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 300)\n",
      "(10000, 18381)\n",
      "KernelRidge(alpha=30, coef0=1, degree=3, gamma=None, kernel='polynomial',\n",
      "      kernel_params=None)\n"
     ]
    }
   ],
   "source": [
    "x_train_all = np.concatenate([x_train_vec, x_dev_vec])\n",
    "y_train_all_pic_bowcaptag_s = np.concatenate([y_train_allpic_bowcaptag_s, y_dev_allpic_bowcaptag_s])\n",
    "\n",
    "parameters = {\"alpha\": [1,5,10,20,30,50],'gamma':[0.01,0.1, 1], \"kernel\":['polynomial']}\n",
    "reg_vec_p_s = GridSearchCV(KernelRidge(), parameters, cv=5,n_jobs=-1)\n",
    "print (x_train_all.shape)\n",
    "print (y_train_all_pic_bowcaptag_s.shape)\n",
    "reg_vec_p_s.fit(y_train_all_pic_bowcaptag_s,x_train_all)\n",
    "print (reg_vec_p_s.best_estimator_)\n",
    "\n",
    "x_test_pred_rid_vec_2_p_s = reg_vec_p_s.predict(y_test_allpic_bowcaptag_s)\n",
    "test_distances_rid_vec_2_p_s = dist_matrix(x_test_pred_rid_vec_2_p_s , x_test_vec).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Word2Vec kernel Ridge(Y= BOW des)  - rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10634)\n",
      "(10000, 18381)\n",
      "KernelRidge(alpha=2, coef0=1, degree=3, gamma=None, kernel='rbf',\n",
      "      kernel_params=None)\n"
     ]
    }
   ],
   "source": [
    "x_train_all_bow = np.concatenate([x_train_bow, x_dev_bow])\n",
    "y_train_all_pic_bowcaptag_s = np.concatenate([y_train_allpic_bowcaptag_s, y_dev_allpic_bowcaptag_s])\n",
    "#print ('x_train_all_bow',x_train_all_bow.shape)\n",
    "#print ('y_train_all_pic_bowcaptag',y_train_all_pic_bowcaptag.shape)\n",
    "print (x_train_all_bow.shape)\n",
    "print (y_train_all_pic_bowcaptag_s.shape)\n",
    "\n",
    "parameters = {\"alpha\": [0.1,1,2,3,5,10], 'kernel':['rbf'],'gamma':[0.01,0.1, 1]}\n",
    "reg_k_s = GridSearchCV(KernelRidge(), parameters, cv=5,n_jobs=-1)\n",
    "reg_k_s.fit(y_train_all_pic_bowcaptag_s,x_train_all_bow)\n",
    "print (reg_k_s.best_estimator_)\n",
    "x_test_pred_rid_bow_2_k_s = reg_k_s.predict(y_test_allpic_bowcaptag_s)\n",
    "test_distances_rid_bow_2_k_s = dist_matrix(x_test_pred_rid_bow_2_k_s, X_test_bow).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Word2Vec kernel Ridge(Y= BOW des)  - polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10634)\n",
      "(10000, 18381)\n",
      "KernelRidge(alpha=50, coef0=1, degree=3, gamma=None, kernel='polynomial',\n",
      "      kernel_params=None)\n"
     ]
    }
   ],
   "source": [
    "x_train_all_bow = np.concatenate([x_train_bow, x_dev_bow])\n",
    "y_train_all_pic_bowcaptag_s = np.concatenate([y_train_allpic_bowcaptag_s, y_dev_allpic_bowcaptag_s])\n",
    "#print ('x_train_all_bow',x_train_all_bow.shape)\n",
    "#print ('y_train_all_pic_bowcaptag',y_train_all_pic_bowcaptag.shape)\n",
    "print (x_train_all_bow.shape)\n",
    "print (y_train_all_pic_bowcaptag_s.shape)\n",
    "\n",
    "parameters = {\"alpha\": [5,20,30,50,80,100,200,500],'gamma':[0.01,0.1, 1], \"kernel\":['polynomial']}\n",
    "reg_p_s = GridSearchCV(KernelRidge(), parameters, cv=5,n_jobs=-1)\n",
    "reg_p_s.fit(y_train_all_pic_bowcaptag_s,x_train_all_bow)\n",
    "print (reg_p_s.best_estimator_)\n",
    "x_test_pred_rid_bow_2_p_s = reg_p_s.predict(y_test_allpic_bowcaptag_s)\n",
    "test_distances_rid_bow_2_p_s = dist_matrix(x_test_pred_rid_bow_2_p_s, X_test_bow).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written!\n"
     ]
    }
   ],
   "source": [
    "test_distances_total = test_distances_rid_vec_2_k_s/test_distances_rid_vec_2_k_s.mean()\\\n",
    "        +  test_distances_rid_bow_2_k_s/test_distances_rid_bow_2_k_s.mean() + \\\n",
    " test_distances_rid_vec_2_p_s/test_distances_rid_vec_2_p_s.mean()\\\n",
    "        +  test_distances_rid_bow_2_p_s/test_distances_rid_bow_2_p_s.mean() \n",
    "\n",
    "pred_rows = []\n",
    "for i in range(num_test):\n",
    "    test_dist_idx = list(np.argsort(test_distances_total[i]))\n",
    "    top_20 = test_dist_idx[:20]\n",
    "    row = [\"%d.jpg\" % i for i in test_dist_idx[:20]]\n",
    "    pred_rows.append(\" \".join(row))\n",
    "\n",
    "with open(\"4KernelRidge_best_model.csv\", \"w\") as f:\n",
    "    f.write(\"Descritpion_ID,Top_20_Image_IDs\\n\")\n",
    "    for i, row in enumerate(pred_rows):\n",
    "        f.write(\"%d.txt,%s\\n\" % (i, row))\n",
    "print(\"Output written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other tried models,  only for reference \n",
    "#### Model 1\n",
    "- X: resnet augmented features (3048*4) + Tags(300)  \n",
    "- 3 models ensemble(1.ridge (Y=BOW des) + 2. ridge(Y= w2v des) + 3. GBM (Y= w2v des)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Word2Vec Ridge(Y= w2v des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = np.concatenate([x_train_vec, x_dev_vec])\n",
    "y_train_all_pic_vectag = np.concatenate([y_train_allpic_vectag, y_dev_allpic_vectag])\n",
    "\n",
    "parameters = {\"alpha\": [30000,40000,50000]}\n",
    "reg_ = GridSearchCV(Ridge(), parameters, cv=5,n_jobs=-1)\n",
    "reg_.fit(y_train_all_pic_vectag,x_train_all)\n",
    "print (reg_.best_estimator_)\n",
    "x_test_pred_rid_vec = reg_.predict(y_test_allpic_vectag)\n",
    "test_distances_rid_vec = dist_matrix(x_test_pred_rid_vec, x_test_vec).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Word2Vec Ridge(Y= BOW des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_all_bow = np.concatenate([x_train_bow, x_dev_bow])\n",
    "y_train_all_pic_vectag = np.concatenate([y_train_allpic_vectag, y_dev_allpic_vectag])\n",
    "print ('x_train_all_bow',x_train_all_bow.shape)\n",
    "print ('y_train_all_pic_vectag',y_train_all_pic_vectag.shape)\n",
    "\n",
    "parameters = {\"alpha\": [30000,40000,50000,60000,70000,80000]}\n",
    "reg_bow = GridSearchCV(Ridge(), parameters, cv=5,n_jobs=-1)\n",
    "reg_bow.fit(y_train_all_pic_vectag, x_train_all_bow)\n",
    "print (reg_bow.best_estimator_)\n",
    "x_test_pred_rid_bow = reg_bow.predict(y_test_allpic_vectag)\n",
    "test_distances_rid_bow = dist_matrix(x_test_pred_rid_bow, X_test_bow).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 GBM (Y= w2v des) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = np.concatenate([x_train_vec, x_dev_vec])\n",
    "y_train_all_pic_vectag = np.concatenate([y_train_allpic_vectag, y_dev_allpic_vectag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [caution]\n",
    "- The following models can be generated by running the code in the next part or download from https://drive.google.com/drive/folders/1pkXLFcvuEkC_VQ-QunVUC9EjjlvF8-j5?usp=sharing (gbm_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if choose to retrain the model (time consuming), pls set train = True\n",
    "train = False\n",
    "if train:\n",
    "    for i in range (300):\n",
    "        gbm = lgb.LGBMRegressor(n_estimators=100, n_jobs=-1).fit(y_train_all, x_train_all[:,i])\n",
    "        gbm.fit(y_train_all_pic_vectag, x_train_all[:,i])\n",
    "        joblib.dump(gbm, \"./gbm_model/t_gbm_all_feature_model_%s.pkl\"%str(i))\n",
    "        del gbm \n",
    "        gc.collect()  \n",
    "    model_list = [joblib.load(\"./gbm_model/gbm_all_feature_model_%s.pkl\"%str(i)) for i in range(300)]\n",
    "    x_test_pred_gbm_vec = np.array([i.predict(y_test_allpic_vectag) for i in model_list ]).T\n",
    "    test_distances_gbm_vec = dist_matrix(x_test_pred, x_test).T\n",
    "else:\n",
    "    model_list = [joblib.load(\"./gbm_model/gbm_all_feature_model_%s.pkl\"%str(i)) for i in range(300)]\n",
    "    x_test_pred_gbm_vec = np.array([i.predict(y_test_allpic_vectag) for i in model_list ]).T\n",
    "    test_distances_gbm_vec= dist_matrix(x_test_pred_gbm_vec, x_test_vec).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble results from models \n",
    "test_distances_total = test_distances_rid_vec + test_distances_rid_bow + test_distances_gbm_vec\n",
    "\n",
    "#output\n",
    "pred_rows = []\n",
    "for i in range(num_test):\n",
    "    test_dist_idx = list(np.argsort(test_distances_total[i]))\n",
    "    top_20 = test_dist_idx[:20]\n",
    "    row = [\"%d.jpg\" % i for i in test_dist_idx[:20]]\n",
    "    pred_rows.append(\" \".join(row))\n",
    "\n",
    "with open(\"other_model_1.csv\", \"w\") as f:\n",
    "    f.write(\"Descritpion_ID,Top_20_Image_IDs\\n\")\n",
    "    for i, row in enumerate(pred_rows):\n",
    "        f.write(\"%d.txt,%s\\n\" % (i, row))\n",
    "\n",
    "print(\"Output written!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "\n",
    "- X: resnet augmented features (3048*4) + BOW Tags + BOW captions\n",
    "- 3 model ensemble(1. ridge(Y=BOW des, X as described above) + 2. Word2Vec Ridge(Y=w2v des,X as described above) + 3. GBM (Y= w2v des, X= resnet augmented features (3048*4) + Tag Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow_vec = np.hstack([x_train_bow, x_train_vec])\n",
    "x_test_bow_vec = np.hstack([X_test_bow, x_test_vec])\n",
    "x_dev_bow_vec = np.hstack([x_dev_bow, x_dev_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_bow_vec = np.hstack([X_test_bow, x_test_vec])\n",
    "x_test_bow_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Word2Vec Ridge(Y= w2v des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all = np.concatenate([x_train_vec, x_dev_vec])\n",
    "y_train_all_pic_bowcaptag = np.concatenate([y_train_allpic_bowcaptag, y_dev_allpic_bowcaptag])\n",
    "#print ('x_train_all_bow',x_train_all.shape)\n",
    "#print ('y_train_all_pic_bowcaptag',y_train_all_pic_bowcaptag.shape)\n",
    "\n",
    "parameters = {\"alpha\": [30000,40000,50000]}\n",
    "reg_vec = GridSearchCV(Ridge(), parameters, cv=5,n_jobs=-1)\n",
    "reg_vec.fit(y_train_all_pic_bowcaptag,x_train_all)\n",
    "#print (reg_vec.best_estimator_)\n",
    "\n",
    "x_test_pred_rid_vec_2 = reg_vec.predict(y_test_allpic_bowcaptag)\n",
    "test_distances_rid_vec_2 = dist_matrix(x_test_pred_rid_vec_2 , x_test_vec).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Word2Vec Ridge(Y= BOW des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_all_bow = np.concatenate([x_train_bow, x_dev_bow])\n",
    "y_train_all_pic_bowcaptag = np.concatenate([y_train_allpic_bowcaptag, y_dev_allpic_bowcaptag])\n",
    "#print ('x_train_all_bow',x_train_all_bow.shape)\n",
    "#print ('y_train_all_pic_bowcaptag',y_train_all_pic_bowcaptag.shape)\n",
    "\n",
    "parameters = {\"alpha\": [30000,40000,50000,60000,70000]}\n",
    "reg = GridSearchCV(Ridge(), parameters, cv=5,n_jobs=-1)\n",
    "reg.fit(y_train_all_pic_bowcaptag,x_train_all_bow)\n",
    "#print (reg.best_estimator_)\n",
    "x_test_pred_rid_bow_2 = reg.predict(y_test_allpic_bowcaptag)\n",
    "test_distances_rid_bow_2 = dist_matrix(x_test_pred_rid_bow_2, X_test_bow).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 GBM (Y= w2v des) \n",
    "- use previous one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble results for model 9\n",
    "test_distances_total = test_distances_rid_vec_2 + test_distances_rid_bow_2 + test_distances_gbm_vec\n",
    "\n",
    "#output\n",
    "pred_rows = []\n",
    "for i in range(num_test):\n",
    "    test_dist_idx = list(np.argsort(test_distances_total[i]))\n",
    "    top_20 = test_dist_idx[:20]\n",
    "    row = [\"%d.jpg\" % i for i in test_dist_idx[:20]]\n",
    "    pred_rows.append(\" \".join(row))\n",
    "\n",
    "with open(\"other_model_2.csv\", \"w\") as f:\n",
    "    f.write(\"Descritpion_ID,Top_20_Image_IDs\\n\")\n",
    "    for i, row in enumerate(pred_rows):\n",
    "        f.write(\"%d.txt,%s\\n\" % (i, row))\n",
    "print(\"Output written!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
